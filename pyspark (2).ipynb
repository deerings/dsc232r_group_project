{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1daa8c-f894-4fee-b74b-2f8ab6b70635",
   "metadata": {},
   "source": [
    "# FEMA's National Flood Insurance Policy Database Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d6da5-22f1-4bde-8d4f-34a969ed9394",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13acd25f-90fc-48eb-823f-370db3aa29af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-4t5gqw31 because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, ByteType, LongType, FloatType, ShortType\n",
    "from pyspark.sql.functions import col, sum as spark_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81025ff1-9dae-4f7a-857e-90a64d6e4179",
   "metadata": {},
   "source": [
    "### Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8b391c-8562-45da-984f-f50a7ec876ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "\t.config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config('spark.executor.instances', 5) \\\n",
    "\t.config(\"spark.sql.debug.maxToStringFields\", \"100\")\\\n",
    "    .appName(\"Flood Data\") \\\n",
    "\t.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918cf43-bfd7-44fd-b72a-ae3fa6b39772",
   "metadata": {},
   "source": [
    "### Load data to Spark dataframe; Infer Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591ba87c-16da-4351-aa84-0c05d5d85139",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#path to data \u001b[39;00m\n\u001b[1;32m      2\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./NFIP/nfip-flood-policies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(data_path)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1706\u001b[0m, in \u001b[0;36mSparkSession.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrameReader:\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;124;03m    Returns a :class:`DataFrameReader` that can be used to read data\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;124;03m    in as a :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;124;03m    +---+------------+\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:70\u001b[0m, in \u001b[0;36mDataFrameReader.__init__\u001b[0;34m(self, spark)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, spark: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkSession\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark \u001b[38;5;241m=\u001b[39m spark\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "#path to data \n",
    "data_path = \"./NFIP/nfip-flood-policies.csv\"\n",
    "\n",
    "df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c74f6e-4b75-4be6-b2a9-8ed7c76216c0",
   "metadata": {},
   "source": [
    "## Perform the Data Exploration\n",
    "Below is the outline of the Data Exploration Section:\n",
    "- Print Schema\n",
    "- Column Description\n",
    "- Display the Number of Variables (Columnns)\n",
    "- Show the First Few Rows\n",
    "- Display Number of Observations\n",
    "- Missing Values in the Dataframe\n",
    "- Statistics Summary and Data Distribution\n",
    "- Correlations Among Variables\n",
    "- Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c2c7c",
   "metadata": {},
   "source": [
    "### Print Schema\n",
    "\n",
    "Understanding the structure of data (column names and types) is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d45cb2-cccb-43e1-bfba-809b1aa61897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06482799",
   "metadata": {},
   "source": [
    "### Column Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "413a5dbb",
   "metadata": {},
   "source": [
    "**Description of the columns from the FEMA's National Flood Insurance Policy Database, grouped by their data types and purpose:**\n",
    "\n",
    "**Geographic and Location Details**\n",
    "- **censustract (long):** Census tract number indicating the specific area where the property is located, used for demographic analysis.\n",
    "- **countycode (integer):** Numeric code representing the county in which the property is insured.\n",
    "- **floodzone (string):** Designation of the flood zone according to FEMA's mapping, crucial for assessing the property's flood risk.\n",
    "- **latitude (double), longitude (double):** Geographic coordinates specifying the precise location of the property.\n",
    "- **propertystate (string):** The U.S. state where the property is located.\n",
    "- **reportedcity (string):** The city reported for the insured property.\n",
    "- **reportedzipcode (integer):** Zip code where the property is situated, used for localizing insurance coverage and risk.\n",
    "\n",
    "**Property and Construction Details**\n",
    "- **agriculturestructureindicator (string):** Indicates whether the property is used for agricultural purposes.\n",
    "- **basementenclosurecrawlspacetype (integer):** Type of basement or crawlspace present at the property, affecting flood risk assessment.\n",
    "- **construction (string):** Describes the type of construction materials and methods used, which can affect the property's vulnerability to flood damage.\n",
    "- **numberoffloorsininsuredbuilding (integer):** Total floors in the insured building, important for determining potential flood damage and insurance coverage needs.\n",
    "- **elevatedbuildingindicator (string):** Indicates whether the building is elevated, a key factor in reducing flood risk.\n",
    "\n",
    "**Policy Details**\n",
    "- **policycost (integer):** The total cost of the flood insurance policy.\n",
    "- **policycount (integer):** The number of policies associated with a single property or account.\n",
    "- **policyeffectivedate (date), policyterminationdate (date):** Start and end dates of the flood insurance coverage.\n",
    "- **totalbuildinginsurancecoverage (integer), totalcontentsinsurancecoverage (integer):** The amount of insurance coverage for the building and its contents, respectively.\n",
    "- **totalinsurancepremiumofthepolicy (integer):** Total premium amount for the flood insurance policy.\n",
    "\n",
    "**Flood Risk Assessment Specifics**\n",
    "- **basefloodelevation (double):** The base flood elevation expected for a particular area, critical for understanding flood risk levels.\n",
    "- **elevationcertificateindicator (string), elevationdifference (integer):** Presence of an elevation certificate and the difference in elevation, respectively, both crucial for assessing compliance with floodplain management.\n",
    "- **lowestadjacentgrade (double), lowestfloorelevation (double):** Measures of elevation that help determine the property's flood exposure.\n",
    "\n",
    "**Insurance Policy Features**\n",
    "- **crsdiscount (double):** Community Rating System discount applied to the policy, which can reduce insurance premiums based on community flood preparedness.\n",
    "- **deductibleamountinbuildingcoverage (integer), deductibleamountincontentscoverage (integer):** Deductible amounts for building and contents coverage, influencing out-of-pocket costs after a flood.\n",
    "- **hfiaasurcharge (integer):** Surcharge applied under the Homeowner Flood Insurance Affordability Act.\n",
    "- **federalpolicyfee (integer):** A fee associated with the federal policy governing flood insurance.\n",
    "\n",
    "**Special Indicators**\n",
    "- **condominiumindicator (string), primaryresidenceindicator (string):** Indicate whether the insured property is a condominium or the primary residence of the owner.\n",
    "- **houseofworshipindicator (string), nonprofitindicator (string):** Indicators of whether the property is used as a house of worship or is owned by a nonprofit organization, affecting policy terms and possibly qualifying for special considerations.\n",
    "- **postfirmconstructionindicator (string):** Indicates if the building was constructed after the community's first Flood Insurance Rate Map was issued, which can affect insurance rates.\n",
    "- **smallbusinessindicatorbuilding (string):** Indicates whether the insured building is used for small business purposes.\n",
    "\n",
    "**Additional Policy and Coverage Information**\n",
    "- **originalconstructiondate (date), originalnbdate (date):** Dates of original construction and the building's initial notebook entry, important for historical property assessments.\n",
    "- **cancellationdateoffloodpolicy (date):** Date when the flood policy was cancelled, if applicable.\n",
    "- **regularemergencyprogramindicator (string):** Indicates the type of FEMA program under which the policy is covered, distinguishing between regular and emergency management programs.\n",
    "- **ratemethod (integer):** Describes the method used to calculate the insurance rate, impacting how premiums are determined.\n",
    "- **locationofcontents (string):** Specifies where within the property the insured contents are located, relevant for claims and risk assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79314eec",
   "metadata": {},
   "source": [
    "### Display number of Variables (Columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067f5ad-5bd4-4c10-920e-554682945ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_variables = len(df.columns)\n",
    "print(\"Number of Columns:\", num_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de894071",
   "metadata": {},
   "source": [
    "### Show the First Few Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc644f3-a9f6-4f22-8b3b-eee3f90b4e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541ea90",
   "metadata": {},
   "source": [
    "### Display Number of Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37f095-f79b-47a4-9761-6a0a220ffa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ea34b",
   "metadata": {},
   "source": [
    "FEMA's National Flood Insurance Policy Database, containing over 50 million (50,406,943) policy transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46603b6",
   "metadata": {},
   "source": [
    "### Missing Values in the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c77deb-7d94-471c-85c3-ceea1fa9ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of missing values in the dataframe\n",
    "missing_vals = df.select(*(spark_sum(col(i).isNull().cast(\"int\")).alias(i) for i in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554286b-9bcf-4465-964f-f0431fbdb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vals.show(vertical= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c68f1",
   "metadata": {},
   "source": [
    "**Here's a description of the missing value situation in the FEMA Flood Insurance Policy Database:** \n",
    "\n",
    "1. **High Missing Values:**\n",
    "- **Base Flood Elevation, Latitude, Longitude, Lowest Adjacent Grade, Lowest Floor Elevation:** These fields each have around 50,406,943 missing values. This suggests a significant lack of geographic and elevation data, which are critical in flood insurance calculations.\n",
    "- **Elevation Certificate Indicator, Elevation Difference:** Both fields are missing approximately 32,806,397 and 32,897,994 values respectively, indicating that elevation certificates, which are vital for verifying compliance with floodplain management regulations, are largely absent.\n",
    "- **Obstruction Type:** Missing around 40,793,526 values, indicating that details about obstructions which can affect flood risk assessments are predominantly not reported.\n",
    "- **House of Worship Indicator, Nonprofit Indicator:** Each has over 34,476,251 and 34,493,094 missing entries respectively, indicating a lack of identification of these property types, which might have different considerations in policy terms.\n",
    "\n",
    "2. **Moderate Missing Values:**\n",
    "- **Deductible Amount in Building Coverage, Deductible Amount in Contents Coverage:** Missing 15,649,149 and 18,265,104 values respectively, which implies incomplete data on policy deductibles that could affect premium calculations and risk assessments.\n",
    "- **Location of Contents:** With 15,389,767 missing entries, there's substantial missing information on where contents are located within the insured buildings, which is vital for damage assessments.\n",
    "\n",
    "3. **Low Missing Values:**\n",
    "- **Census Tract, Flood Zone:** Missing 467,119 and 169,145 entries respectively. Although relatively lower, these still represent significant gaps, especially as these fields are crucial for location-specific risk assessment.\n",
    "- **Number of Floors in Insured Building:** Missing data on 162,301 entries could affect understanding building structure and associated risk.\n",
    "\n",
    "4. **Minimal to No Missing Values:**\n",
    "- Fields like **CRS Discount, Federal Policy Fee**, and various policy-related dates (effectiveness, termination) and costs show zero missing values, indicating complete data in terms of policy transaction details.\n",
    "- Similarly, **County Code, Construction, Condominium Indicator, Occupancy Type** show minimal missing data (under 50,000), suggesting good coverage of basic property and policyholder information.\n",
    "\n",
    "Overall, the dataset shows a strong presence of policy and basic property information but suffers from a significant absence of detailed geographic and structural data. This gap in data can hamper effective risk assessment and pricing of flood insurance policies, especially in areas prone to flooding where such data is most critical. Addressing these missing values, either by data imputation where appropriate or by collecting missing data, could significantly enhance the robustness of any analysis or predictive modeling based on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0471c",
   "metadata": {},
   "source": [
    "### Statistics Summary and Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [col_name for col_name, data_type in df.dtypes if data_type in [\"int\", \"bigint\", \"double\"]]\n",
    "\n",
    "# Select only numerical columns\n",
    "numerical_df = df.select(*numerical_columns)\n",
    "\n",
    "# Generate summary statistics\n",
    "summary_stats = numerical_df.describe()\n",
    "\n",
    "# Show summary statistics\n",
    "summary_stats.show(vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1b200",
   "metadata": {},
   "source": [
    "The summary statistics for the FEMA National Flood Insurance Policy Database provide a comprehensive overview of various policy and property-related numerical attributes. These statistics include measures of central tendency, dispersion, and range, all of which are critical for understanding the distribution and potential data quality issues within the dataset. Below is a detailed analysis of the key statistical summaries:\n",
    "\n",
    "**Central Tendency and Dispersion**\n",
    "1. **Base Flood Elevation:**\n",
    "- Average (Mean): 119.47 ft.\n",
    "- Standard Deviation: 522.49 ft.\n",
    "- Range: -9999 - 85,640 ft.\n",
    "2. **Lowest Adjacent Grade:**\n",
    "- Average (Mean): 129.20 ft.\n",
    "- Standard Deviation: 609.92 ft.\n",
    "- Range: -9,999 - 99,990.9 ft.\n",
    "3. **Lowest Floor Elevation:**\n",
    "- Average (Mean): 385.62 ft.\n",
    "- Standard Deviation: 1,676.42 ft.\n",
    "- Range: -9,997.9 - 99,989 ft.\n",
    "4. **Basement Enclosure Crawl Space Type:**\n",
    "- Average (Mean): 0.37, indicating a slight bias towards lower classifications.\n",
    "- Standard Deviation: 0.86, showing moderate variability within the data.\n",
    "- Range: Min 0 to Max 4, spanning several classification levels.\n",
    "5. **Census Tract:**\n",
    "- Average (Mean): Approximately 2.6 x 10¹⁰.\n",
    "- Standard Deviation: About 1.58 x 10¹⁰, suggesting a wide spread across census tracts.\n",
    "6. **CRS Discount:**\n",
    "- Average: 0.064, typically low across the dataset.\n",
    "- Standard Deviation: 0.091, with most data points close to zero but some higher values.\n",
    "7. **Deductible Amount in Building and Contents Coverage:**\n",
    "- Building Coverage Average: 1.66 with a deviation of 1.46.\n",
    "- Contents Coverage Average: 0.98 with a deviation of 1.05.\n",
    "- Both show low average deductible amounts but with notable variation.\n",
    "8. **Elevation Difference:**\n",
    "- Average: 1.69, indicating minor differences in elevation on average.\n",
    "- Standard Deviation: 3.39, suggesting significant outliers affecting the elevation difference.\n",
    "9. **Policy Related Figures (Policy Cost, Policy Count, Total Insurance Coverage, etc.):**\n",
    "- These values have a high mean and standard deviation, indicating a significant spread in the policy costs and coverages, reflecting diverse insurance policies and property valuations.\n",
    "\n",
    "**Extremes (Minimum and Maximum Values)**\n",
    "- Notable minimums include negative values in **Federal Policy Fee and HFIAA Surcharge**, possibly indicating refunds or adjustments.\n",
    "- The maximum values in **Total Building Insurance Coverage and Total Insurance Premium of the Policy** reach into the hundreds of millions, highlighting cases with exceptionally high insurance coverage.\n",
    "\n",
    "**Implications**\n",
    "The substantial missing data in critical geographical and elevation columns could significantly hinder risk assessment accuracy. The wide variability in policy costs and coverage levels underscores the diverse nature of the insured properties. Accurate and complete data in these fields are crucial for effective risk management and policy pricing in flood insurance.\n",
    "\n",
    "This analysis provides a basis for further data cleaning, particularly in addressing missing values and outliers, which are essential for improving data quality and the reliability of subsequent analyses and decision-making processes based on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c08be-71bc-4c28-823e-d1b2537cc6d6",
   "metadata": {},
   "source": [
    "### Correlations Among Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de39205-bbba-4da1-8a6a-aa5b67e4855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d99a1-7348-4b2c-a42a-1aee2231685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_col = \"features\"\n",
    "input = numerical_df.columns\n",
    "output = [v_col + str(i) for i in range(len(input))]\n",
    "imputer = Imputer(strategy='mean',inputCols=input,outputCols=output)\n",
    "changed_df = imputer.fit(numerical_df).transform(numerical_df) \n",
    "\n",
    "assembler = VectorAssembler(inputCols=output,outputCol=v_col)\n",
    "numerical_df_vector = assembler.transform(changed_df).select(v_col)\n",
    "numerical_df_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a84814-8007-4d66-9ff1-a65c567c8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = Correlation.corr(numerical_df_vector,v_col).collect()[0][0]\n",
    "corr_matrix = matrix.toArray().tolist()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7fb26-e714-4477-8744-0ee9f7099bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc495c-9b0c-4c2a-862a-e3911976008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['basefloodelevation',\n",
    " 'basementenclosurecrawlspacetype',\n",
    " 'censustract',\n",
    " 'countycode',\n",
    " 'crsdiscount',\n",
    " 'elevationdifference',\n",
    " 'federalpolicyfee',\n",
    " 'hfiaasurcharge',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'lowestadjacentgrade',\n",
    " 'lowestfloorelevation',\n",
    " 'numberoffloorsininsuredbuilding',\n",
    " 'occupancytype',\n",
    " 'policycost',\n",
    " 'policycount',\n",
    " 'policytermindicator',\n",
    " 'totalbuildinginsurancecoverage',\n",
    " 'totalcontentsinsurancecoverage',\n",
    " 'totalinsurancepremiumofthepolicy']\n",
    "df_c = spark.createDataFrame(corr_matrix,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd59ba2-1e7e-48af-aab5-ce12e63ebbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('basefloodelevation',\n",
    " 'basementenclosurecrawlspacetype',\n",
    " 'censustract').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310dcee-68c8-452a-a83f-20273013c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('countycode',\n",
    " 'crsdiscount',\n",
    " 'elevationdifference').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca97081-e7db-4b49-b4ef-63ebd3cf3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('federalpolicyfee',\n",
    " 'hfiaasurcharge',\n",
    " 'latitude').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cad91-59a1-47e7-a55e-4bac354bca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('longitude',\n",
    " 'lowestadjacentgrade',\n",
    " 'lowestfloorelevation').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852d6f6-8a18-46c7-bbdf-d9444f9fe7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('numberoffloorsininsuredbuilding',\n",
    " 'occupancytype',\n",
    " 'policycost').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8bef1-6303-4d11-9636-0b03ea59ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('policycount',\n",
    " 'policytermindicator',\n",
    " 'totalbuildinginsurancecoverage').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add942fc-df40-4bfd-b481-ccc8d8a561c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.select('totalcontentsinsurancecoverage',\n",
    " 'totalinsurancepremiumofthepolicy').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c070f80-06aa-4100-ad23-ec46429cfd59",
   "metadata": {},
   "source": [
    "The dataframe new_df is the dataframe with the imputed mean values and this code checks that there are zero missing values and the column names are changed from feature0, feature1 and so on to the original column names within the new_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6c40c-952f-4142-bb58-ef0d6ce813c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = changed_df.drop('basefloodelevation',\n",
    " 'basementenclosurecrawlspacetype',\n",
    " 'censustract',\n",
    " 'countycode',\n",
    " 'crsdiscount',\n",
    " 'elevationdifference',\n",
    " 'federalpolicyfee',\n",
    " 'hfiaasurcharge',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'lowestadjacentgrade',\n",
    " 'lowestfloorelevation',\n",
    " 'numberoffloorsininsuredbuilding',\n",
    " 'occupancytype',\n",
    " 'policycost',\n",
    " 'policycount',\n",
    " 'policytermindicator',\n",
    " 'totalbuildinginsurancecoverage',\n",
    " 'totalcontentsinsurancecoverage',\n",
    " 'totalinsurancepremiumofthepolicy')\n",
    "new_df.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32070b59-92cf-4db7-a782-65dd7bab243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_missing_vals = new_df.select(*(spark_sum(col(i).isNull().cast(\"int\")).alias(i) for i in new_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91818d10-cebf-454c-a0f1-a0a3bcbb3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_missing_vals.show(vertical= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967b8f8-115b-4026-998f-302c1719de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['basefloodelevation',\n",
    " 'basementenclosurecrawlspacetype',\n",
    " 'censustract',\n",
    " 'countycode',\n",
    " 'crsdiscount',\n",
    " 'elevationdifference',\n",
    " 'federalpolicyfee',\n",
    " 'hfiaasurcharge',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'lowestadjacentgrade',\n",
    " 'lowestfloorelevation',\n",
    " 'numberoffloorsininsuredbuilding',\n",
    " 'occupancytype',\n",
    " 'policycost',\n",
    " 'policycount',\n",
    " 'policytermindicator',\n",
    " 'totalbuildinginsurancecoverage',\n",
    " 'totalcontentsinsurancecoverage',\n",
    " 'totalinsurancepremiumofthepolicy']\n",
    "new_df = new_df.toDF(*column_names)\n",
    "new_df.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91cdc1-2ab9-433a-bc72-dc2243b32a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edba34-6010-47f6-83be-5df33ed90094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Construct Linear Regression model to perform Feature Importance (find weights of features, choose top weights' features to keep)\n",
    "# creating train and test sets\n",
    "# X = new_df.drop('totalinsurancepremiumofthepolicy')\n",
    "# y = df['totalinsurancepremiumofthepolicy']\n",
    "# ASK: Is 'features' correct?\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['basefloodelevation',\n",
    " 'basementenclosurecrawlspacetype',\n",
    " 'censustract',\n",
    " 'countycode',\n",
    " 'crsdiscount',\n",
    " 'elevationdifference',\n",
    " 'federalpolicyfee',\n",
    " 'hfiaasurcharge',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'lowestadjacentgrade',\n",
    " 'lowestfloorelevation',\n",
    " 'numberoffloorsininsuredbuilding',\n",
    " 'occupancytype',\n",
    " 'policycost',\n",
    " 'policycount',\n",
    " 'policytermindicator',\n",
    " 'totalbuildinginsurancecoverage',\n",
    " 'totalcontentsinsurancecoverage'],\n",
    "    outputCol = 'features')\n",
    "new_df = assembler.transform(new_df)\n",
    "final_data = new_df.select('features', 'totalinsurancepremiumofthepolicy')\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium', regParam = 0.3)\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593fcd9-da7e-4e1b-98c1-b78588ca6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Print coefficients of the features (will run this cell AFTER LinReg is successful)\n",
    "coefficients = lr_model.coefficients\n",
    "print(\"Coefficients: {}\".format(lr_model.coefficients)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47538ebb-f710-4749-8f53-27ef6999ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Construct Feature Importance to find top 10 features to choose to represent our dataset.\n",
    "feature_importance = sorted(list(zip(new_df.columns[:-1], map(abs, coefficients))), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(\"  {}: {:.3f}\".format(feature, importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b264f4b-fe62-4a73-9677-f760ec3fcd8c",
   "metadata": {},
   "source": [
    "# Construct 5 Linear Regression Models to find Ideal Range for Model Complexity\n",
    "#### Using the Feature Importance model information, will start by training a Linear Regression Model with 1 feature (Top Feature Importance), then 5 features, 10 features, 15 features, and finally 19 features. There are a total 20 numerical features in the FEMA dataset, and the totalinsurancepremiumofthepolicy feature is the dependent variable. \n",
    "\n",
    "### Linear Regression Model with 1 Feature: crsdiscount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5551d2d-146e-4d18-a789-115708fb22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_f1 = VectorAssembler(\n",
    "    inputCols=['crsdiscount'], outputCol = 'predict_features_1')\n",
    "\n",
    "new_df = assembler_f1.transform(new_df)\n",
    "\n",
    "df_f1 = new_df.select('predict_features_1', 'totalinsurancepremiumofthepolicy')\n",
    "train_data_f1, test_data_f1 = df_f1.randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "lr_f1 = LinearRegression(featuresCol = 'predict_features_1', labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f1', regParam = 0.3)\n",
    "lr_model_f1 = lr_f1.fit(train_data_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac0cb3-e0eb-469c-854d-cd9b90b7346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Train data\n",
    "predictions_rmse_train_f1 = lr_model_f1.transform(train_data_f1)\n",
    "\n",
    "evaluator_f1 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f1', metricName = 'rmse')\n",
    "rmse_train_f1 = evaluator.evaluate(predictions_rmse_train_f1)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data for Linear Regression using 1 feature: {:.7f}\".format(rmse_train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701eac2-346c-451c-b91d-0d22b82a1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Train data\n",
    "evaluator_r2_f1 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f1', metricName = 'r2')\n",
    "r2_train_f1 = evaluator_r2_f1.evaluate(predictions_rmse_train_f1)\n",
    "print(\"R-squared (R2) on train data for Linear Regression using 1 feature: {:.7f}\".format(r2_train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe0cc9-7dbd-4e28-bebf-e3573dcc684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Test data\n",
    "predictions_rmse_test_f1 = lr_model_2.transform(test_data_f1)\n",
    "\n",
    "evaluator_f1 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f1', metricName = 'rmse')\n",
    "rmse_test_f1 = evaluator.evaluate(predictions_rmse_test_f1)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Linear Regression using 1 feature: {:.7f}\".format(rmse_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b5519d-c7eb-4ffe-8f30-c3e09802e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Test data\n",
    "evaluator_r2_f1 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f1', metricName = 'r2')\n",
    "r2_test_f1 = evaluator_r2_f1.evaluate(predictions_rmse_test_f1)\n",
    "print(\"R-squared (R2) on test data for Linear Regression using 1 feature: {:.7f}\".format(r2_test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08f857-c94c-47a9-8810-2e1f8579ca49",
   "metadata": {},
   "source": [
    "### Linear Regression Model with 5 Features: \n",
    "#### crsdiscount', 'policytermindicator', 'occupancytype', 'policycount', basementenclosurecrawlspacetype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905b89f-5c7b-46cb-9d55-dcfeccd49ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_f5 = VectorAssembler(\n",
    "    inputCols=['crsdiscount',\n",
    "  'policytermindicator',\n",
    "  'occupancytype',\n",
    "  'policycount',\n",
    "  'basementenclosurecrawlspacetype'], outputCol = 'predict_features_5')\n",
    "\n",
    "new_df = assembler_f5.transform(new_df)\n",
    "\n",
    "df_f5 = new_df.select('predict_features_5', 'totalinsurancepremiumofthepolicy')\n",
    "train_data_f5, test_data_f5 = df_f5.randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "lr_f5 = LinearRegression(featuresCol = 'predict_features_5', labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f5', regParam = 0.3)\n",
    "lr_model_f5 = lr_f5.fit(train_data_f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9377b-792c-4da2-b5f4-84bf9ed49a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Train data\n",
    "predictions_rmse_train_f5 = lr_model_f5.transform(train_data_f5)\n",
    "\n",
    "evaluator_f5 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f5', metricName = 'rmse')\n",
    "rmse_train_f5 = evaluator.evaluate(predictions_rmse_train_f5)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data for Linear Regression using 5 features: {:.7f}\".format(rmse_train_f5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aae0e-2edb-402a-a1db-1ce5e221d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Train data\n",
    "evaluator_r2_f5 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f5', metricName = 'r2')\n",
    "r2_train_f5 = evaluator_r2_f5.evaluate(predictions_rmse_train_f5)\n",
    "print(\"R-squared (R2) on train data for Linear Regression using 5 features: {:.7f}\".format(r2_train_f5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7e997-9d6c-419a-b05f-4a987d42a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Test data\n",
    "predictions_rmse_test_f5 = lr_model_2.transform(test_data_f5)\n",
    "\n",
    "evaluator_f5 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f5', metricName = 'rmse')\n",
    "rmse_test_f5 = evaluator.evaluate(predictions_rmse_test_f5)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Linear Regression using 5 features: {:.7f}\".format(rmse_test_f5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead9b56-8b4f-4526-a5d4-03e3696306d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Test data\n",
    "evaluator_r2_f5 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f5', metricName = 'r2')\n",
    "r2_test_f5 = evaluator_r2_f5.evaluate(predictions_rmse_test_f5)\n",
    "print(\"R-squared (R2) on test data for Linear Regression using 5 features: {:.7f}\".format(r2_test_f5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a35d3-c236-4ffb-a64d-7ffe9993b640",
   "metadata": {},
   "source": [
    "### Linear Regression Model with 10 Features:\n",
    "#### 'basementenclosurecrawlspacetype', 'crsdiscount', 'federalpolicyfee', 'hfiaasurcharge', 'latitude', 'numberoffloorsininsuredbuilding', 'occupancytype', 'policycost', 'policycount', 'policytermindicator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3436f1-b2e9-430b-b668-95eea5508254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Construct Linear Regression prediction model with the new Chosen 10 Features\n",
    "# f10 = LinReg model with top 10 features (chosen from Feature Importance)\n",
    "\n",
    "assembler_f10 = VectorAssembler(\n",
    "    inputCols=['basementenclosurecrawlspacetype',\n",
    " 'crsdiscount',\n",
    " 'federalpolicyfee',\n",
    " 'hfiaasurcharge',\n",
    " 'latitude',\n",
    " 'numberoffloorsininsuredbuilding',\n",
    " 'occupancytype',\n",
    " 'policycost',\n",
    " 'policycount',\n",
    " 'policytermindicator'],\n",
    "    outputCol = 'predict_features_10')\n",
    "\n",
    "new_df = assembler_f10.transform(new_df)\n",
    "\n",
    "df_f10 = new_df.select('predict_features_10', 'totalinsurancepremiumofthepolicy')\n",
    "train_data_f10, test_data_f10 = df_f10.randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "lr_f10 = LinearRegression(featuresCol = 'predict_features_10', labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f10', regParam = 0.3)\n",
    "lr_model_f10 = lr_f10.fit(train_data_f10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bab97a-19b3-424d-9a22-04580ceb2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: RMSE for Train data\n",
    "# RMSE ranges from 0 to infinity, lower RMSE the better, (higher weight to larger errors)\n",
    "predictions_rmse_train_f10 = lr_model_f10.transform(train_data_f10)\n",
    "\n",
    "evaluator_f10 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f10', metricName = 'rmse')\n",
    "rmse_train_f10 = evaluator.evaluate(predictions_rmse_train)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data for Linear Regression using 10 features: {:.7f}\".format(rmse_train_f10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919290e-ad2a-4fa4-aa6f-9903ce0a8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Train data\n",
    "evaluator_r2_f10 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f10', metricName = 'r2')\n",
    "r2_train_f10 = evaluator_r2_f10.evaluate(predictions_rmse_train_f10)\n",
    "print(\"R-squared (R2) on train data for Linear Regression using 10 features: {:.7f}\".format(r2_train_f10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51187e9-29b6-4ff8-b881-30118c37a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Test data\n",
    "predictions_rmse_test_f10 = lr_model_2.transform(test_data_f10)\n",
    "\n",
    "evaluator_f10 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f10', metricName = 'rmse')\n",
    "rmse_test_f10 = evaluator.evaluate(predictions_rmse_test_f10)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Linear Regression using 10 features: {:.7f}\".format(rmse_test_f10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937352cf-d6ee-4e64-aef7-d8aa4abb68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Test data\n",
    "evaluator_r2_f10 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f10', metricName = 'r2')\n",
    "r2_test_f10 = evaluator_r2_f10.evaluate(predictions_rmse_test_f10)\n",
    "print(\"R-squared (R2) on test data for Linear Regression using 10 features: {:.7f}\".format(r2_test_f10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff452090-d2c7-47a5-9d6b-c291bdce2303",
   "metadata": {},
   "source": [
    "### Linear Regression Model with 15 Features\n",
    "#### 'crsdiscount', 'policytermindicator', 'occupancytype', 'policycount', 'basementenclosurecrawlspacetype', 'hfiaasurcharge', 'federalpolicyfee', 'policycost', 'numberoffloorsininsuredbuilding', 'latitude', 'longitude', 'elevationdifference', 'lowestadjacentgrade', 'lowestfloorelevation', 'basefloodelevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f344e6-94c7-409e-aaab-48263bacbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_f15 = VectorAssembler(\n",
    "    inputCols=['crsdiscount',\n",
    "  'policytermindicator',\n",
    "  'occupancytype',\n",
    "  'policycount',\n",
    "  'basementenclosurecrawlspacetype',\n",
    "  'hfiaasurcharge',\n",
    "  'federalpolicyfee',\n",
    "  'policycost',\n",
    "  'numberoffloorsininsuredbuilding',\n",
    "  'latitude',\n",
    "  'longitude',\n",
    "  'elevationdifference',\n",
    "  'lowestadjacentgrade',\n",
    "  'lowestfloorelevation',\n",
    "  'basefloodelevation'], outputCol = 'predict_features_15')\n",
    "\n",
    "new_df = assembler_f15.transform(new_df)\n",
    "\n",
    "df_f15 = new_df.select('predict_features_15', 'totalinsurancepremiumofthepolicy')\n",
    "train_data_f15, test_data_f15 = df_f15.randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "lr_f15 = LinearRegression(featuresCol = 'predict_features_15', labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f15', regParam = 0.3)\n",
    "lr_model_f15 = lr_f15.fit(train_data_f15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e08ef-971b-46a6-ae84-07a2778f0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Train data\n",
    "predictions_rmse_train_f15 = lr_model_f15.transform(train_data_f15)\n",
    "\n",
    "evaluator_f15 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f15', metricName = 'rmse')\n",
    "rmse_train_f15 = evaluator.evaluate(predictions_rmse_train_f15)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data for Linear Regression using 15 features: {:.7f}\".format(rmse_train_f15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3556b-8a48-4320-b816-4fc47968f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Train data\n",
    "evaluator_r2_f15 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f15', metricName = 'r2')\n",
    "r2_train_f15 = evaluator_r2_f15.evaluate(predictions_rmse_train_f15)\n",
    "print(\"R-squared (R2) on train data for Linear Regression using 15 features: {:.7f}\".format(r2_train_f15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc61ffb-6b44-417b-85d4-e966aadfc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Test data\n",
    "predictions_rmse_test_f15 = lr_model_2.transform(test_data_f15)\n",
    "\n",
    "evaluator_f15 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f15', metricName = 'rmse')\n",
    "rmse_test_f15 = evaluator.evaluate(predictions_rmse_test_f15)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Linear Regression using 15 features: {:.7f}\".format(rmse_test_f15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eead96-f5ca-4322-bb55-01340066780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Test data\n",
    "evaluator_r2_f15 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f15', metricName = 'r2')\n",
    "r2_test_f15 = evaluator_r2_f15.evaluate(predictions_rmse_test_f15)\n",
    "print(\"R-squared (R2) on test data for Linear Regression using 15 features: {:.7f}\".format(r2_test_f15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73f50d-88a3-4705-9c3d-5eb18e28c744",
   "metadata": {},
   "source": [
    "### Linear Regression Model with 19 Features\n",
    "#### 'crsdiscount', 'policytermindicator', 'occupancytype', 'policycount', 'basementenclosurecrawlspacetype', 'hfiaasurcharge', 'federalpolicyfee', 'policycost', 'numberoffloorsininsuredbuilding', 'latitude', 'longitude', 'elevationdifference', 'lowestadjacentgrade:', 'lowestfloorelevation', 'basefloodelevation', 'countycode', 'totalbuildinginsurancecoverage', 'totalcontentsinsurancecoverage', 'censustract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca92a9-8c6c-491a-a241-c530db3e917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_f19 = VectorAssembler(\n",
    "    inputCols = ['crsdiscount',\n",
    "  'policytermindicator',\n",
    "  'occupancytype',\n",
    "  'policycount',\n",
    "  'basementenclosurecrawlspacetype',\n",
    "  'hfiaasurcharge',\n",
    "  'federalpolicyfee',\n",
    "  'policycost',\n",
    "  'numberoffloorsininsuredbuilding',\n",
    "  'latitude',\n",
    "  'longitude',\n",
    "  'elevationdifference',\n",
    "  'lowestadjacentgrade:',\n",
    "  'lowestfloorelevation',\n",
    "  'basefloodelevation',\n",
    "  'countycode',\n",
    "  'totalbuildinginsurancecoverage',\n",
    "  'totalcontentsinsurancecoverage',\n",
    "  'censustract'], outputCol = 'predict_features_19')\n",
    "\n",
    "new_df = assembler_f19.transform(new_df)\n",
    "\n",
    "df_f19 = new_df.select('predict_features_15', 'totalinsurancepremiumofthepolicy')\n",
    "train_data_f19, test_data_f19 = df_f19.randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "lr_f19 = LinearRegression(featuresCol = 'predict_features_19', labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f19', regParam = 0.3)\n",
    "lr_model_f19 = lr_f19.fit(train_data_f19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb16f7-e533-4802-8097-1b132ee0cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Train data\n",
    "predictions_rmse_train_f19 = lr_model_f19.transform(train_data_f19)\n",
    "\n",
    "evaluator_f19 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f19', metricName = 'rmse')\n",
    "rmse_train_f19 = evaluator.evaluate(predictions_rmse_train_f19)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data for Linear Regression using 19 features: {:.7f}\".format(rmse_train_f19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae9771-65ba-481b-a89a-a05312a9fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Train data\n",
    "evaluator_r2_f19 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f19', metricName = 'r2')\n",
    "r2_train_f19 = evaluator_r2_f19.evaluate(predictions_rmse_train_f19)\n",
    "print(\"R-squared (R2) on train data for Linear Regression using 19 features: {:.7f}\".format(r2_train_f19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcbac42-ecb9-43a0-82f3-6f75b4f817a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for Test data\n",
    "predictions_rmse_test_f19 = lr_model_2.transform(test_data_f19)\n",
    "\n",
    "evaluator_f19 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f19', metricName = 'rmse')\n",
    "rmse_test_f19 = evaluator.evaluate(predictions_rmse_test_f19)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Linear Regression using 19 features: {:.7f}\".format(rmse_test_f19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14faef-79df-489a-904f-409f68d00b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared for Test data\n",
    "evaluator_r2_f19 = RegressionEvaluator(labelCol = 'totalinsurancepremiumofthepolicy', predictionCol = 'predicted_premium_f19', metricName = 'r2')\n",
    "r2_test_f19 = evaluator_r2_f19.evaluate(predictions_rmse_test_f19)\n",
    "print(\"R-squared (R2) on test data for Linear Regression using 19 features: {:.7f}\".format(r2_test_f19))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6030344-6e0e-46c8-ac37-13f55f69de0e",
   "metadata": {},
   "source": [
    "## Note to group: exclude Bar plots when submitting for Milestone 4. This is incorrect; not a Fitting Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb8d98-7c5a-4249-9701-c3e1f7325141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Bar plot with RMSE values, comparing train and test data\n",
    "# To answer Question 4: \"Where does your model fit in the fitting graph?\"\n",
    "df_barplot = pd.DataFrame({'RMSE': ['Train RMSE', 'Test RMSE'], 'Error Values': [118.133, 117.118]})  \n",
    "df_barplot.plot.bar(x = 'RMSE', y = 'Error Values')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f587a-87c6-4f2c-a769-7e2a71e3e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Bar plot with R-squared values, comparing train and test data\n",
    "# To answer Question 4: \"Where does your model fit in the fitting graph?\"\n",
    "df_barplot = pd.DataFrame({'R-Squared': ['Train R-Squared', 'Test R-Squared'], 'Values': [0.995, 0.995]})  \n",
    "df_barplot.plot.bar(x = 'R-Squared', y = 'Values')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5b933-e369-4bee-b609-6d70597657ff",
   "metadata": {},
   "source": [
    "### Scatterplots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554a239-9402-4b17-901d-258733d8d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_num_df = changed_df.sample(False, 0.1)\n",
    "num_pdf = changed_num_df.toPandas()\n",
    "print(num_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b2830-1613-4da2-9cd1-060dc91ba3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=num_pdf['policycost'],y=num_pdf['totalinsurancepremiumofthepolicy'])\n",
    "plt.xlabel('Policy Cost')\n",
    "plt.ylabel('Total Insurance Premium of the Policy')          \n",
    "plt.title('Policy Cost vs Total Insurance Premium of the Policy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdeceeb-ca90-4ffb-9ca1-28125c9acfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=num_pdf['countycode'],y=num_pdf['censustract'])\n",
    "plt.xlabel('County Code')\n",
    "plt.ylabel('Census Tract') \n",
    "plt.title('County Code vs Census Tract')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eadc63-86f7-4727-9c8a-0bcd96481610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(x=num_pdf['policycount'],y=num_pdf['totalbuildinginsurancecoverage'])\n",
    "plt.xlabel('Policy Count')\n",
    "plt.ylabel('Total Building Insurance Coverage') \n",
    "plt.title('Policy Count vs Total Building Insurance Coverage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f37dc5-570b-4029-9d7e-4e063db265ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
